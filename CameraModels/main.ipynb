{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Camera Models\n",
    "Source : Chapter 6 of Multiple View Geometry in Computer Vision.\n",
    "\n",
    "## Introduction\n",
    "A camera is a mapping between the 3D world and a 2D image. Camera models are matrices that represent this mapping.\n",
    "\n",
    "## The basic pinhole model\n",
    "Under the pinhole model, a point in space with homogeneous coordinates $X = (x, y, z, 1)$ is mapped to the point on the image where a line joining the 3D point to the center of projection (the pinhole) meets the imager plane.\n",
    "\n",
    "### Central projection model\n",
    "This allows us to define the pinhole model of central projection as the mapping\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{pmatrix}\n",
    "x \\\\\n",
    "y \\\\\n",
    "z \\\\\n",
    "1\n",
    "\\end{pmatrix}\n",
    "\\mapsto\n",
    "\\begin{pmatrix}\n",
    "fx \\\\\n",
    "fy \\\\\n",
    "z\n",
    "\\end{pmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "f &   &   & 0 \\\\\n",
    "  & f &   & 0 \\\\\n",
    "  &   & 1 & 1 \\\n",
    "\\end{bmatrix}\n",
    "\\begin{pmatrix}\n",
    "x \\\\\n",
    "y \\\\\n",
    "z \\\\\n",
    "1\n",
    "\\end{pmatrix}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "### Principal point offset\n",
    "In the previous expression, we assume that the origin of the coordinates in the image plane is at the principal point (center of projection), ie at the center of the image.\n",
    "In practice this may not be the case, in fact we usually use a corner of the image as origin.\n",
    "Therefore we want to be able to add an offset to the projected points in the image. If we choose $(p_x, p_y)$ to be the coordinates of the principal point, then this can be expressed as \n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{pmatrix}\n",
    "x \\\\\n",
    "y \\\\\n",
    "z \\\\\n",
    "1\n",
    "\\end{pmatrix}\n",
    "\\mapsto\n",
    "\\begin{pmatrix}\n",
    "fx + zp_x\\\\\n",
    "fy + zp_y\\\\\n",
    "z\n",
    "\\end{pmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "f &   &p_x& 0 \\\\\n",
    "  & f &p_y& 0 \\\\\n",
    "  &   & 1 & 1\n",
    "\\end{bmatrix}\n",
    "\\begin{pmatrix}\n",
    "x \\\\\n",
    "y \\\\\n",
    "z \\\\\n",
    "1\n",
    "\\end{pmatrix}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "We kan isolate the matrix $K = \\begin{bmatrix}\n",
    "f &   &p_x& 0 \\\\\n",
    "  & f &p_y& 0 \\\\\n",
    "  &   & 1 & 1 \\\n",
    "\\end{bmatrix}$, that is called the camera calibration matrix.\n",
    "\n",
    "This allowed us to move from the camera coordinate frame (Z down) to the image frame. This transformation is summarized as $$x = K [I | 0]X_{cam}$$.\n",
    "\n",
    "### Camera rotation and translation\n",
    "In general, points are not expressed in the camera coordinate frame but in the world coordinate frame.\n",
    "These two frames are related via a rotation and translation.\n",
    "To go from world to camera frame, we first translate the world point, then we rotate it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a69d40d4541aa5b8653f6b4004427542deb1ae314227ba25ee4a7524cf82509a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
